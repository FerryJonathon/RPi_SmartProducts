{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc10a6da",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "### Jonathon Ferry\n",
    "\n",
    "### Problem 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89db6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ git clone https://github.com/tensorflow/examples --depth 1\n",
    "$ sudo apt install libportaudio2\n",
    "$ cd ~/examples/lite/examples/object_detection/raspberry_pi\n",
    "$ sh setup.sh\n",
    "$ python3 detect.py --model efficientdet_lite0.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb82e65",
   "metadata": {},
   "source": [
    "The detection model was really good at picking things up in the image. The model is trained very generally, since it seems to pick up things that aren't there. I wonder if it would seem to work better if it only displayed boxes around objects it detected with high confidence. I also had good success testing with individual objects while facing the camera up\n",
    "\n",
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbca4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ cd ~/examples/lite/examples/object_detection/raspberry_pi\n",
    "$ cp ~/raspberrypi_cookbook_ed4/python/ch_09_person_detector.py .\n",
    "$ python3 ch_09_person_detector.py\n",
    "\n",
    "# Had to download book code from section 3.22 (page 94)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ecc79",
   "metadata": {},
   "source": [
    "This code used the same model as the previous code, but used it to respond to objects in the image. In addition, it saves the image when the object is detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12528f",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2214ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (962619535.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    $ git clone https://github.com/tensorflow/examples --depth 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$ git clone https://github.com/tensorflow/examples --depth 1\n",
    "\n",
    "# Had to clone into a new directory. Ran into error \"Destination path already exists\"\n",
    "$ mkdir book_examples\n",
    "\n",
    "$ cd ~/examples/lite/examples/sound_classification/raspberry_pi\n",
    "\n",
    "# Setup line gave significant trouble. Tried running as sudo.\n",
    "# Error: gfortran module (among others) wasn't found. Run lines to download:\n",
    "$ sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran\n",
    "$ sudo apt-get install libopenblas-dev\n",
    "\n",
    "$ sh setup.sh\n",
    "\n",
    "# Had to fix tensorflow plot error in /examples/sound_classification/raspberry_pi/utils.py\n",
    "# Lines 64-65:\n",
    "label_list = [category.category_name for category in classification.categories]\n",
    "score_list = [category.score for category in classification.categories]\n",
    "\n",
    "# For microphone to work, went to adafruit braincraft audio install page. Ran following commands:\n",
    "# Note: This is only for braincraft hat. Run in a new terminal\n",
    "$ git clone https://github.com/HinTak/seeed-voicecard\n",
    "$ cd seeed-voicecard/\n",
    "$ git checkout v5.9\n",
    "$ sudo ./install.sh\n",
    "$ sudo reboot\n",
    "\n",
    "python3 classify.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d7e4f",
   "metadata": {},
   "source": [
    "This problem had some extensive troubleshooting. Once working, I was amazed at the complexity of sound identified. Music, laughter, shouting, talking, etc. Really, really cool. Learned a lot about libraries while troubleshooting too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2187c",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ cp ~/raspberrypi_cookbook_ed4/python/ch_09_detect_whistle.py .\n",
    "$ python3 ch_09_detect_whistle.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564380e",
   "metadata": {},
   "source": [
    "This code worked on the first try. It works very well, and shows an interesting implementation of the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ce7fc",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ curl -sL https://deb.nodesource.com/setup_12.x | sudo bash -\n",
    "\n",
    "# This line worked, but the file included in the github is NOT correct. Copy directly from book.\n",
    "$ sudo apt install -y gcc g++ make build-essential nodejs sox gstreamer1.0-tools gstreamer1.0-plugins-good gstreamer1.0-plugins-base gstreamer1.0-plugins-base-apps\n",
    "\n",
    "$ npm config set user root && sudo npm install edge-impulse-linux -g --unsafe-perm\n",
    "\n",
    "$ pip3 install numpy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684203a",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf87a35",
   "metadata": {},
   "source": [
    "Followed on screen commands to make a neural network to detect \"Hey pi\". Collected training data using microphone, then trained using simulated background noise. After that, it trained, and returned a model with 97.7% accuracy. Woah!!! The website seems really easy to use and might be powerful enough to make interesting personal projects. It looks like it can detect things in sensor data as well, so it could be useful in tandem with electromechanical systems, not just audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d014c9",
   "metadata": {},
   "source": [
    "### Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00834860",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ edge-impulse-linux-runner --clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15787f",
   "metadata": {},
   "source": [
    "Followed in-terminal commands to build a local version of the model used in problem 6. Worked very well, similar to above. Surprisingly quick."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf44e40",
   "metadata": {},
   "source": [
    "### Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ sudo apt install libatlas-base-dev libportaudio0 libportaudio2 libportaudiocpp0 portaudio19-dev\n",
    "$ pip3 install edge_impulse_linux -i https://oreil.ly/ua1nS\n",
    "$ pip3 install numpy --upgrade\n",
    "$ pip3 install pyaudio\n",
    "\n",
    "$ edge-impulse-linux-runner --download modelfile.eim\n",
    "\n",
    "$ python3 07_hey_pi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import signal\n",
    "from edge_impulse_linux.audio import AudioImpulseRunner\n",
    "\n",
    "modelfile = '/home/jonathonferry/modelfile.eim'\n",
    "audio_device_id = 2\n",
    "\n",
    "runner = None\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    print('Interrupted')\n",
    "    if (runner):\n",
    "        runner.stop()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "\n",
    "with AudioImpulseRunner(modelfile) as runner:\n",
    "    try:\n",
    "        model_info = runner.init()\n",
    "        labels = model_info['model_parameters']['labels']\n",
    "        print('Loaded runner for \"' + model_info['project']['owner'] + ' / ' + model_info['project']['name'] + '\"')\n",
    "\n",
    "        for res, audio in runner.classifier(device_id=audio_device_id):\n",
    "            score = res['result']['classification']['hey_pi']\n",
    "            if (score > 0.7):\n",
    "                print('Hello you!')\n",
    "\n",
    "    finally:\n",
    "        if (runner):\n",
    "            runner.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82023ef",
   "metadata": {},
   "source": [
    "To finish the trio, we integrated the model into our own python script. This is pretty incredible how simple it is to create and integrate robust neural network models. This could be very powerful for personal projects as well. Kam had the idea to make a \"hey chat GPT\" system that would identify when activated, then listen, and feed your input into chat GPT automatically, then turn the response into audio and read it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af83188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
